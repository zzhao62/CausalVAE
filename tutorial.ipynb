{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalVAE\n",
    "A tutorial on how to do Causal Inference using Variational AutoEncoder.\n",
    "\n",
    "## Learning Disentanglement Representation\n",
    "Causal inference is the process to determine the actual effect of treatment on the outcome. To achieve this, we need to estimate the relationship between different variables. This is where learning the disentanglement representation can be helpful. \n",
    "\n",
    "According to the definition by *[deep ai](https://deepai.org/machine-learning-glossary-and-terms/disentangled-representation-learning)*:\n",
    ">Disentangled representation is an unsupervised learning technique that breaks down, or disentangles, each feature into narrowly defined variables and encodes them as separate dimensions.\n",
    "\n",
    "Using disentanglement representation, we can generate samples that do not exist at the beginning. For example, if our original samples are car a facing front and car b with color red, once we learn the disentangled representation, we can use this net to generate a new car c facing front with color red.\n",
    "\n",
    "![[]](https://images.deepai.org/glossary-terms/0f4d258be4b8465e93a7cd888ba19543/disentangledrep.jpg)\n",
    "\n",
    "## Variational Autoencoder\n",
    "Variational Autoencoder is a popular method to learn disentangled representation. The model has two parts: inference nets as an encoder and generative nets as a decoder. The encoder first maps all the features into a latent space. Then we can generate new features using the decoder. In causal inference, we can use the generative nets to give us counterfactual distributions. For more details about variational autoencoder, you can refer to [*Tutorial on Variational Autoencoders*](https://arxiv.org/abs/1606.05908)\n",
    "\n",
    "![[]](https://miro.medium.com/max/1400/1*UdOybs9wOe3zW8vDAfj9VA@2x.png)\n",
    "\n",
    "## Causal Variational Autoencoder\n",
    "There are three steps to apply Variational Autoencoder to Causal Inference in pratice: \n",
    "* Determine the causal model\n",
    "* Build inference nets and generative nets based on the causal model\n",
    "* Determine the optimization goal\n",
    "* Train the model\n",
    "* Estimate the causal effects based on our nets\n",
    "\n",
    "### Determine the Causal Model\n",
    "Assume that we have the following causal model. T is the treatment. y is the outcome. And x are other features other than the treatment. Notice that the causal model is preassumed in practice. It needs field knowledge and expert experience to determine such a causal model. Our neural networks are tools to estimate the parameters of functions. \n",
    "![[]](./source/causal_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build inference and generative nets based on the causal model\n",
    "The causal model is composed of three generative nets and three inference nets. We use $q$ to notate inference nets and $p$ to notate generative nets. Generative nets can generate sample from distributions given conditions. For example, $p(x|z)$ means that we can output the probability distributions of $x$ given $z$.\n",
    "\n",
    "There are two kinds of features in the data: binary and continuous. Treatment t is ususally a binary data. It should be either 0 or 1. To fit the distribution of binary data, we can use Bernoulli distribution $t \\sim B(p ,1)$. The parameter here we want to know is the probability $p$. We can forward a linear layer to a softmax function to get the parameter $p$. The following code shows how to build a binary net in pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import bernoulli, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a network with binary output\n",
    "class bin_net(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in,dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        self.dim_out = dim_out\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        self.output = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.input(x))\n",
    "        # calculate probabilities \n",
    "        out_p = torch.sigmoid(self.output(x))\n",
    "        # generate binary output from bernoulli distribution\n",
    "        out = bernoulli.Bernoulli(out_p)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another kind of data is continuous. For simplicity, we can use normal distributions to reconstruct the data. We need to estimate $\\mu$ and $\\sigma$ to fit a normal distribution $x \\sim N(\\mu, \\sigma)$. Thus, we build two layers to estimate $\\mu$ and $\\sigma$ respectively. The following code shows how to build a continuous net in pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a network with continuous output\n",
    "class cont_net(nn.Module):\n",
    "    \n",
    "    def __init__(self,dim_in, dim_h=20, dim_out_con=6):\n",
    "        super().__init__()\n",
    "        self.dim_out_con = dim_out_con\n",
    "\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        # for continuous output, mu and sigma are estimated\n",
    "        self.output_con_mu = nn.Linear(dim_h, dim_out_con)\n",
    "        self.output_con_sigma = nn.Linear(dim_h, dim_out_con)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_input):\n",
    "        z = F.elu(self.input(z_input))\n",
    "        # for continuous outputs\n",
    "        mu, sigma = self.output_con_mu(z), self.softplus(self.output_con_sigma(z))\n",
    "        out = normal.Normal(mu, sigma)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build a network to represent the conditional distribution. Take $p(y|z,t)$ as an example. We want to estimate the distribution of $y$ given $z$ and $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_y_zt(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=20, nh=3, dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # Separated forwards for different t values, TAR\n",
    "\n",
    "        self.input_t0 = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden_t0 = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.mu_t0 = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "        self.input_t1 = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden_t1 = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.mu_t1 = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        # Separated forwards for different t values, TAR\n",
    "\n",
    "        x_t0 = F.elu(self.input_t0(z))\n",
    "        for i in range(self.nh):\n",
    "            x_t0 = F.elu(self.hidden_t0[i](x_t0))\n",
    "        mu_t0 = F.elu(self.mu_t0(x_t0))\n",
    "\n",
    "        x_t1 = F.elu(self.input_t1(z))\n",
    "        for i in range(self.nh):\n",
    "            x_t1 = F.elu(self.hidden_t1[i](x_t1))\n",
    "        mu_t1 = F.elu(self.mu_t1(x_t1))\n",
    "        y_bin_p = torch.sigmoid((1-t)*mu_t0 + t * mu_t1)\n",
    "        return y_bin_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build other networks in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(x|z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_x_z(nn.Module):\n",
    "    def __init__(self,dim_in=20, nh=3, dim_h=20, dim_out_bin=19, dim_out_con=6):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.dim_out_bin = dim_out_bin\n",
    "        self.dim_out_con = dim_out_con\n",
    "\n",
    "        # dim in is the dim of latent space z\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully connected hidden layers\n",
    "        self.hidden = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh-1)])\n",
    "        # output binary layers\n",
    "        self.output_bin = nn.Linear(dim_h, dim_out_bin)\n",
    "        # for continuous output, mu and sigma are estimated\n",
    "        self.output_con_mu = nn.Linear(dim_h, dim_out_con)\n",
    "        self.output_con_sigma = nn.Linear(dim_h, dim_out_con)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, z_input):\n",
    "        z = F.elu(self.input(z_input))\n",
    "        for i in range(self.nh-1):\n",
    "            z = F.elu(self.hidden[i](z))\n",
    "        # for binary output\n",
    "        x_bin_p = torch.sigmoid(self.output_bin(z))\n",
    "        x_bin = bernoulli.Bernoulli(x_bin_p)\n",
    "        # for continuous outputs\n",
    "        mu, sigma = self.output_con_mu(z), self.softplus(self.output_con_sigma(z))\n",
    "        x_con = normal.Normal(mu, sigma)\n",
    "        return x_bin, x_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(t|z)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class p_t_z(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=20, nh=1, dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # dim_in is dim of latent space z\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.output = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.input(x))\n",
    "        for i in range(self.nh):\n",
    "            x = F.elu(self.hidden[i](x))\n",
    "        # for binary outputs:\n",
    "        out_p = torch.sigmoid(self.output(x))\n",
    "\n",
    "        out = bernoulli.Bernoulli(out_p)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(y|z,t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class p_y_zt(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=20, nh=3, dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # Separated forwards for different t values, TAR\n",
    "\n",
    "        self.input_t0 = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden_t0 = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.mu_t0 = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "        self.input_t1 = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden_t1 = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.mu_t1 = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        # Separated forwards for different t values, TAR\n",
    "\n",
    "        x_t0 = F.elu(self.input_t0(z))\n",
    "        for i in range(self.nh):\n",
    "            x_t0 = F.elu(self.hidden_t0[i](x_t0))\n",
    "        mu_t0 = F.elu(self.mu_t0(x_t0))\n",
    "\n",
    "        x_t1 = F.elu(self.input_t1(z))\n",
    "        for i in range(self.nh):\n",
    "            x_t1 = F.elu(self.hidden_t1[i](x_t1))\n",
    "        mu_t1 = F.elu(self.mu_t1(x_t1))\n",
    "        y_bin_p = torch.sigmoid((1-t)*mu_t0 + t * mu_t1)\n",
    "        return y_bin_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q(t|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_t_x(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=25, nh=1, dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.dim_out = dim_out\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        self.hidden = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        self.output = nn.Linear(dim_h, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.input(x))\n",
    "        for i in range(self.nh):\n",
    "            x = F.elu(self.hidden[i](x))\n",
    "        # for binary outputs:\n",
    "        out_p = torch.sigmoid(self.output(x))\n",
    "        out = bernoulli.Bernoulli(out_p)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q(y|x,t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_y_xt(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=25, nh=3, dim_h=20, dim_out=1):\n",
    "        super().__init__()\n",
    "        # save required vars\n",
    "        self.nh = nh\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # dim_in is dim of data x\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "        # separate outputs for different values of t\n",
    "        self.mu_t0 = nn.Linear(dim_h, dim_out)\n",
    "        self.mu_t1 = nn.Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Unlike model network, shared parameters with separated heads\n",
    "        x = F.elu(self.input(x))\n",
    "        for i in range(self.nh):\n",
    "            x = F.elu(self.hidden[i](x))\n",
    "        # only output weights separated\n",
    "        mu_t0 = self.mu_t0(x)\n",
    "        mu_t1 = self.mu_t1(x)\n",
    "        # set mu according to t, sigma set to 1\n",
    "        y_bin_p = torch.sigmoid((1-t)*mu_t0 + t * mu_t1)\n",
    "        # set mu according to t value\n",
    "        return y_bin_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$q(z|t,y,x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class q_z_tyx(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in=25+1, nh=3, dim_h=20, dim_out=20):\n",
    "        super().__init__()\n",
    "        # dim in is dim of x + dim of y\n",
    "        # dim_out is dim of latent space z\n",
    "        self.nh = nh\n",
    "\n",
    "        # Shared layers with separated output layers\n",
    "\n",
    "        self.input = nn.Linear(dim_in, dim_h)\n",
    "        # loop through dimensions to create fully con. hidden layers, add params with ModuleList\n",
    "        self.hidden = nn.ModuleList([nn.Linear(dim_h, dim_h) for _ in range(nh)])\n",
    "\n",
    "        self.mu_t0 = nn.Linear(dim_h, dim_out)\n",
    "        self.mu_t1 = nn.Linear(dim_h, dim_out)\n",
    "        self.sigma_t0 = nn.Linear(dim_h, dim_out)\n",
    "        self.sigma_t1 = nn.Linear(dim_h, dim_out)\n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, xy, t):\n",
    "        # Shared layers with separated output layers\n",
    "        x = F.elu(self.input(xy))\n",
    "        for i in range(self.nh):\n",
    "            x = F.elu(self.hidden[i](x))\n",
    "        mu_t0 = self.mu_t0(x)\n",
    "        mu_t1 = self.mu_t1(x)\n",
    "        sigma_t0 = self.softplus(self.sigma_t0(x))\n",
    "        sigma_t1 = self.softplus(self.sigma_t1(x))\n",
    "\n",
    "        # Set mu and sigma according to t\n",
    "        z = normal.Normal((1-t)*mu_t0 + t * mu_t1, (1-t)*sigma_t0 + t * sigma_t1)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization goal of a VAE is ELBO. In short, the loss function is composed of two parts: reconstruction loss and KL divergence. The reconstruction loss is also called generative loss. It measures whether our generated $x$, $y$ and $t$ are close to the orginal. And KLD is also called latent loss. This loss term penalizes the VAE if it starts to produce latent vectors that are not from the desired distribution. For more details about optimization objective of VAE, please refer to  [*Tutorial on Variational Autoencoders*](https://arxiv.org/abs/1606.05908)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CreditDataset' from 'models.datasets' (/Users/zz/pyprojects/CausalVAE/models/datasets.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_1/1wb9crvj68d_t9x1vcj4_9pc0000gn/T/ipykernel_30497/2890268520.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCreditDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CreditDataset' from 'models.datasets' (/Users/zz/pyprojects/CausalVAE/models/datasets.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models.datasets import CreditDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import normal, bernoulli\n",
    "from torch import optim\n",
    "from models.networks import p_t_z, p_x_z, p_y_zt, q_t_x, q_y_xt, q_z_tyx\n",
    "from models.initialize import init_qz\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Hyper-parameters\n",
    "M = 1000\n",
    "epochs = 50\n",
    "lr = 0.0001\n",
    "decay = 0.001\n",
    "print_every = 10\n",
    "z_dim = 20\n",
    "h_dim = 64\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# read data\n",
    "trainset = CreditDataset(M,path=\"../data/credit_train.csv\")\n",
    "testset = CreditDataset(M, path=\"../data/credit_test.csv\")\n",
    "\n",
    "(xtr, ttr, ytr) = (trainset.data_x, trainset.data_t, trainset.data_y)\n",
    "(xte, tte, yte) = (testset.data_x, testset.data_t, testset.data_y)\n",
    "\n",
    "\n",
    "binfeats = trainset.bin_feats\n",
    "confeats = trainset.con_feats\n",
    "perm = binfeats+confeats\n",
    "\n",
    "xtr, xte = xtr[:, perm], xte[:, perm]\n",
    "\n",
    "x_dim = len(binfeats) + len(confeats)\n",
    "\n",
    "# initialize the networks\n",
    "p_x_z_dist = p_x_z(dim_in=z_dim, nh=1, dim_h=h_dim, dim_out_bin=len(binfeats), dim_out_con=len(confeats)).to(device)\n",
    "p_t_z_dist = p_t_z(dim_in=z_dim, nh=1, dim_h=h_dim, dim_out=1).to(device)\n",
    "p_y_zt_dist = p_y_zt(dim_in=z_dim, nh=1, dim_h=h_dim, dim_out=1).to(device)\n",
    "q_t_x_dist = q_t_x(dim_in=x_dim, nh=1, dim_h=h_dim, dim_out=1).to(device)\n",
    "q_y_xt_dist = q_y_xt(dim_in=x_dim, nh=1, dim_h=h_dim, dim_out=1).to(device)\n",
    "q_z_tyx_dist = q_z_tyx(dim_in=x_dim+1, nh=1, dim_h=h_dim, dim_out=z_dim).to(device)\n",
    "\n",
    "p_z_dist = normal.Normal(torch.zeros(z_dim).to(device), torch.ones(z_dim).to(device))\n",
    "\n",
    "params = list(p_x_z_dist.parameters()) + \\\n",
    "         list(p_t_z_dist.parameters()) + \\\n",
    "         list(p_y_zt_dist.parameters()) + \\\n",
    "         list(q_t_x_dist.parameters()) + \\\n",
    "         list(q_y_xt_dist.parameters()) + \\\n",
    "         list(q_z_tyx_dist.parameters())\n",
    "\n",
    "# init q_z inference\n",
    "q_z_tyx_dist = init_qz(q_z_tyx_dist, p_z_dist, ytr, ttr, xtr)\n",
    "\n",
    "optimizer = optim.Adam(params, lr=lr, weight_decay=decay)\n",
    "\n",
    "n_epoch, n_iter_per_epoch, idx = epochs, 10 * int(xtr.shape[0] / M), list(range(xtr.shape[0]))\n",
    "\n",
    "loss = defaultdict(list)\n",
    "\n",
    " # store loss per epoch\n",
    "loss_history_store = {'Total': [],\n",
    "                    'Reconstr_x_bin': [],\n",
    "                    'Reconstr_x_con': [],\n",
    "                    'Reconstr_t': [],\n",
    "                    'Reconstr_y': [],\n",
    "                    'Regularization': []}\n",
    "\n",
    "for epoch in range(n_epoch+1):\n",
    "    # print('Epoch: %i/%i' % (epoch, n_epoch))\n",
    "    loss_sum = 0.\n",
    "    # shuffle index\n",
    "    np.random.shuffle(idx)\n",
    "    # take random batch for training\n",
    "\n",
    "    loss_epoch_store = {'Total': [],\n",
    "                    'Reconstr_x_bin': [],\n",
    "                    'Reconstr_x_con': [],\n",
    "                    'Reconstr_t': [],\n",
    "                    'Reconstr_y': [],\n",
    "                    'Regularization': []}\n",
    "\n",
    "    for j in range(n_iter_per_epoch):\n",
    "        # select random batch\n",
    "        batch = np.random.choice(idx, M)\n",
    "        x_train, y_train, t_train = torch.FloatTensor(xtr[batch]), torch.FloatTensor(ytr[batch]), \\\n",
    "                                        torch.FloatTensor(ttr[batch])\n",
    "        x_train = x_train.to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        t_train = t_train.to(device)\n",
    "\n",
    "        # inferred distribution over z\n",
    "        xy = torch.cat((x_train, y_train), 1)\n",
    "        z_infer = q_z_tyx_dist(xy=xy, t=t_train)\n",
    "        # use a single sample to approximate expectation in lowerbound\n",
    "        z_infer_sample = z_infer.sample()\n",
    "\n",
    "        # RECONSTRUCTION LOSS\n",
    "        # p(x|z)\n",
    "        x_bin, x_con = p_x_z_dist(z_infer_sample)\n",
    "        l1 = x_bin.log_prob(x_train[:, :len(binfeats)]).sum(1)\n",
    "        loss['Reconstr_x_bin'].append(l1.mean().cpu().detach().float())\n",
    "        loss_epoch_store['Reconstr_x_bin'].append(l1.mean().cpu().detach().float())\n",
    "        l2 = x_con.log_prob(x_train[:, -len(confeats):]).sum(1)\n",
    "        loss['Reconstr_x_con'].append(l2.mean().cpu().detach().float())\n",
    "        loss_epoch_store['Reconstr_x_con'].append(l2.mean().cpu().detach().float())\n",
    "        # p(t|z)\n",
    "        t = p_t_z_dist(z_infer_sample)\n",
    "        l3 = t.log_prob(t_train).squeeze()\n",
    "        loss['Reconstr_t'].append(l3.mean().cpu().detach().float())\n",
    "        loss_epoch_store['Reconstr_t'].append(l3.mean().cpu().detach().float())\n",
    "        # p(y|t,z)\n",
    "        # for training use t_train, in out-of-sample prediction this becomes t_infer\n",
    "        y = p_y_zt_dist(z_infer_sample, t_train)\n",
    "        y = bernoulli.Bernoulli(y)\n",
    "        l4 = y.log_prob(y_train).squeeze()\n",
    "        loss['Reconstr_y'].append(l4.mean().cpu().detach().float())\n",
    "        loss_epoch_store['Reconstr_y'].append(l4.mean().cpu().detach().float())\n",
    "        # REGULARIZATION LOSS\n",
    "        # p(z) - q(z|x,t,y)\n",
    "        # approximate KL\n",
    "        l5 = (p_z_dist.log_prob(z_infer_sample) - z_infer.log_prob(z_infer_sample)).sum(1)\n",
    "        # Analytic KL (seems to make overall performance less stable)\n",
    "        loss['Regularization'].append(l5.mean().cpu().detach().float())\n",
    "        loss_epoch_store['Regularization'].append(l5.mean().cpu().detach().float())\n",
    "\n",
    "        # Total objective\n",
    "        # inner sum to calculate loss per item, torch.mean over batch\n",
    "        loss_mean = torch.mean(l1 + l2 + l3 + l4 + l5)\n",
    "        loss['Total'].append(loss_mean.cpu().detach().numpy())\n",
    "        loss_epoch_store['Total'].append(loss_mean.cpu().detach().numpy())\n",
    "        objective = -loss_mean\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Calculate gradients\n",
    "        objective.backward()\n",
    "        # Update step\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_history_store['Total'].append(-np.mean(loss_epoch_store['Total']))\n",
    "    loss_history_store['Reconstr_x_bin'].append(-np.mean(loss_epoch_store['Reconstr_x_bin']))\n",
    "    loss_history_store['Reconstr_x_con'].append(-np.mean(loss_epoch_store['Reconstr_x_con']))\n",
    "    loss_history_store['Reconstr_t'].append(-np.mean(loss_epoch_store['Reconstr_t']))\n",
    "    loss_history_store['Reconstr_y'].append(-np.mean(loss_epoch_store['Reconstr_y']))\n",
    "    loss_history_store['Regularization'].append(-np.mean(loss_epoch_store['Regularization']))\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('Epoch %i' % epoch)\n",
    "        for k, v in loss_history_store.items():\n",
    "            print(\"{}: {}\".format(k, v[-1]))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(loss['Total']), label='Total')\n",
    "plt.title('Variational Lower Bound')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "subidx = 1\n",
    "for key, value in loss.items():\n",
    "    plt.subplot(2, 4, subidx)\n",
    "    plt.tight_layout()\n",
    "    plt.plot(-np.array(value), label=key)\n",
    "    plt.title(key)\n",
    "    subidx += 1\n",
    "plt.show()\n",
    "\n",
    "with open('../results/train_history.pkl', 'wb') as f:\n",
    "    pickle.dump(loss_history_store, f)\n",
    "    \n",
    "torch.save({\n",
    "            'p_x_z_dist': p_x_z_dist.state_dict(),\n",
    "            'p_t_z_dist': p_t_z_dist.state_dict(),\n",
    "            'p_y_zt_dist': p_y_zt_dist.state_dict(),\n",
    "            'q_t_x_dist': q_t_x_dist.state_dict(),\n",
    "            'q_y_xt_dist': q_y_xt_dist.state_dict(),\n",
    "            'q_z_tyx_dist': q_z_tyx_dist.state_dict()\n",
    "            }, \"../results/nets.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d80f4afbd5ee8c26af7d41392552c7675a905d46d6ab595bc0d79a5765c7b923"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
